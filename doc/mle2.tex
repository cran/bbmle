\documentclass{article}
\usepackage[utf8]{inputenc} % for UTF-8/single quotes from sQuote()
\author{Ben Bolker}
\title{Maximum likelihood estimation and analysis
  with the {\tt bbmle} package}
\newcommand{\code}[1]{{\tt #1}}
\date{\today}
\usepackage{/usr/local/lib/R/share/texmf/Sweave}
\begin{document}
\bibliographystyle{plain}
\maketitle


The \code{bbmle} package, designed to make it easier to
do maximum likelihood estimation and analysis in R,
extends and modifies the \code{mle} function and class
in the \code{stats4} package that comes with R by default;
\code{mle} is in turn a wrapper around the \code{optim}
function in base R.
The maximum-likelihood-estimation function and class
in \code{bbmle} are both called \code{mle2}, to avoid
confusion and conflict with the original functions in
the \code{stats4} package.  The major differences between
\code{mle} and \code{mle2} are:
\begin{itemize}
\item \code{mle2} is slightly
   more robust, with additional warnings (e.g.
  if the Hessian can't be computed by finite differences,
  \code{mle2} returns a fit with a missing Hessian rather
  than stopping with an error)
\item \code{mle2} uses a \code{data} argument to allow different
  data to be passed to the negative log-likelihood function
\item formula interface
\item \code{bbmle} defines {\tt anova}, {\tt AIC}, and {\tt BIC} methods for
  \code{mle2} objects, as well as
  \code{AICtab}, \code{BICtab}, \code{AICctab}
  functions for producing summary tables of information criteria for a 
  set of models
\end{itemize}

\section{Example}

This example will use the classic data set on
\emph{Orobanche} germination from \cite{Crowder1978}
(you can also use
\code{glm(...,family="quasibinomial")} or
the \code{aod} package to analyze these data).


\subsection{Test basic fit to simulated beta-binomial data}

First, generate a single beta-binomially distributed
set of points as a simple test.

Implement beta-binomial distribution (density and random-deviate function):
\begin{Schunk}
\begin{Sinput}
> dbetabinom <- function(x, mu, size, theta, log = FALSE) {
+     v <- lchoose(size, x) - lbeta(theta * (1 - mu), theta * mu) + 
+         lbeta(size - x + theta * (1 - mu), x + theta * mu)
+     if (log) 
+         v
+     else exp(v)
+ }
> rbetabinom <- function(n, mu, size, theta) {
+     a <- theta * mu
+     b <- theta * (1 - mu)
+     rbinom(n, size = size, prob = rbeta(n, a, b))
+ }
\end{Sinput}
\end{Schunk}

Generate random deviates from a random beta-binomial:
\begin{Schunk}
\begin{Sinput}
> set.seed(1001)
> x1 = rbetabinom(n = 1000, mu = 0.1, size = 50, theta = 10)
\end{Sinput}
\end{Schunk}

Load the package:
\begin{Schunk}
\begin{Sinput}
> library(bbmle)
\end{Sinput}
\end{Schunk}

Construct a simple negative log-likelihood function:
\begin{Schunk}
\begin{Sinput}
> mtmp <- function(mu, size, theta) {
+     -sum(dbetabinom(x1, mu, size, theta, log = TRUE))
+ }
\end{Sinput}
\end{Schunk}

Fit the model:

\begin{Schunk}
\begin{Sinput}
> m0 <- mle2(mtmp, start = list(mu = 0.2, theta = 9), data = list(size = 50))
> m0
\end{Sinput}
\begin{Soutput}
Call:
mle2(minuslogl = mtmp, start = list(mu = 0.2, theta = 9), data = list(size = 50))

Coefficients:
        mu      theta 
 0.1030974 10.0758090 

Log-likelihood: -2723.5 
\end{Soutput}
\end{Schunk}

The \code{summary} method for \code{mle2} objects
shows the parameters; approximate standard
errors (based on quadratic approximation to the curvature at
the maximum likelihood estimate); and a test
of the parameter difference from zero based on
this standard error and on an assumption of normality.

\begin{Schunk}
\begin{Sinput}
> summary(m0)
\end{Sinput}
\begin{Soutput}
Maximum likelihood estimation

Call:
mle2(minuslogl = mtmp, start = list(mu = 0.2, theta = 9), data = list(size = 50))

Coefficients:
        Estimate Std. Error z value     Pr(z)    
mu     0.1030974  0.0031624  32.601 < 2.2e-16 ***
theta 10.0758090  0.6213191  16.217 < 2.2e-16 ***
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 

-2 log L: 5446.995 
\end{Soutput}
\end{Schunk}

Construct the likelihood profile (you can
apply e.g. \code{confint} directly to \code{m0},
but if you're going to work with the likelihood
profile (e.g. plotting, or looking for confidence
intervals at several different $\alpha$ values)
then it is more efficient to compute the profile
once):

\begin{Schunk}
\begin{Sinput}
> p0 <- profile(m0)
\end{Sinput}
\end{Schunk}

Compare the confidence interval estimates based on
a spline fit to the profile (the default)
and based on the quadratic approximation.
\begin{Schunk}
\begin{Sinput}
> confint(p0)
\end{Sinput}
\begin{Soutput}
           2.5 %     97.5 %
mu    0.09709228  0.1095103
theta 8.91708211 11.3559591
\end{Soutput}
\begin{Sinput}
> confint(m0, method = "quad")
\end{Sinput}
\begin{Soutput}
           2.5 %     97.5 %
mu    0.09689929  0.1092955
theta 8.85804600 11.2935720
\end{Soutput}
\end{Schunk}

The curvature-based confidence
limits are very close to the profile confidence
limits.

Plot the profiles:
\begin{Schunk}
\begin{Sinput}
> par(mfrow = c(1, 2))
> plot(p0, plot.confstr = TRUE)
\end{Sinput}
\end{Schunk}
\includegraphics{mle2-010}

The plot method for 
likelihood profiles displays the square root of the
the deviance
(twice the difference in negative
log-likelihood), so it will
be {\sf V}-shaped
for cases where the quadratic approximation works well
(as in this case).

You can also request confidence intervals
calculated using \code{uniroot}, which may be more exact when
the profile is not smooth enough to be modeled accurately
by a spline.  However, this method is
also more sensitive to numeric problems; in this
case it works poorly because we have not constrained
the parameters to be in the required ranges
($0<\mu<1$, $0<\theta$).

Instead of defining an
explicit function for \code{minuslogl}, 
we can use the formula interface.
The formula interface assumes that
the density function given (1) has \code{x} as
its first argument (if the distribution is multivariate,
then \code{x} should be a matrix of observations)
and (2) has a \code{log} argument that will return
the log-probability or log-probability density
if \code{log=TRUE}.
\begin{Schunk}
\begin{Sinput}
> m0f <- mle2(x1 ~ dbetabinom(mu, size = 50, theta), start = list(mu = 0.2, 
+     theta = 9))
\end{Sinput}
\end{Schunk}

It's convenient to use the formula interface
to try out likelihood estimation on the
transformed parameters:
\begin{Schunk}
\begin{Sinput}
> m0cf <- mle2(x1 ~ dbetabinom(mu = plogis(lmu), size = 50, theta = exp(ltheta)), 
+     start = list(lmu = 0, ltheta = 2))
> confint(m0cf, method = "uniroot")
\end{Sinput}
\begin{Soutput}
           2.5 %    97.5 %
lmu    -2.229963 -2.095757
ltheta  2.187950  2.429744
\end{Soutput}
\begin{Sinput}
> confint(m0cf, method = "spline")
\end{Sinput}
\begin{Soutput}
Profiling...
           2.5 %    97.5 %
lmu    -2.229963 -2.095756
ltheta  2.187948  2.429742
\end{Soutput}
\end{Schunk}

In this case the answers from \code{uniroot}
and \code{spline} (default) methods barely
differ.

\subsection{Using real data}
Get data from Crowder 1978 \cite{Crowder1978},
as incorporated in the {\tt aod} package:
\begin{Schunk}
\begin{Sinput}
> library(aod)
> data(orob1)
\end{Sinput}
\end{Schunk}

Now construct a negative log-likelihood
function that differentiates among groups:
\begin{Schunk}
\begin{Sinput}
> ml1 <- function(mu1, mu2, mu3, theta, x) {
+     mu <- c(mu1, mu2, mu3)[as.numeric(x$dilution)]
+     size <- x$n
+     -sum(dbetabinom(x$y, mu, size, theta, log = TRUE))
+ }
\end{Sinput}
\end{Schunk}

Results from \cite{Crowder1978}:
% latex.default(crowder.results, file = "", table.env = FALSE,      title = "model") 
%
\begin{center}
 \begin{tabular}{lrrrrrrrr}\hline\hline
\multicolumn{1}{l}{model}&
\multicolumn{1}{c}{mu1}&
\multicolumn{1}{c}{mu2}&
\multicolumn{1}{c}{mu3}&
\multicolumn{1}{c}{theta}&
\multicolumn{1}{c}{sd.mu1}&
\multicolumn{1}{c}{sd.mu2}&
\multicolumn{1}{c}{sd.mu3}&
\multicolumn{1}{c}{NLL}
\\ \hline
prop diffs&$0.132$&$0.871$&$0.839$&$78.424$&$0.027$&$0.028$&$0.032$&$-34.991$\\
full model&$$&$$&$$&$$&$$&$$&$$&$-34.829$\\
homog model&$$&$$&$$&$$&$$&$$&$$&$-56.258$\\
\hline
\end{tabular}

\end{center}                            
\begin{Schunk}
\begin{Sinput}
> m1 <- mle2(ml1, start = list(mu1 = 0.5, mu2 = 0.5, mu3 = 0.5, 
+     theta = 1), data = list(x = orob1))
> m1
\end{Sinput}
\begin{Soutput}
Call:
mle2(minuslogl = ml1, start = list(mu1 = 0.5, mu2 = 0.5, mu3 = 0.5, 
    theta = 1), data = list(x = orob1))

Coefficients:
       mu1        mu2        mu3      theta 
 0.1318405  0.8706131  0.8382921 73.6011216 

Log-likelihood: -34.99 

Warning: optimization did not converge (code 1)
\end{Soutput}
\end{Schunk}

The result warns us that the optimization has not
converged; we also don't match
Crowder's results for $\theta$ exactly.
We can fix this by setting \code{parscale} appropriately.

\begin{Schunk}
\begin{Sinput}
> m2 <- mle2(ml1, start = as.list(coef(m1)), control = list(parscale = coef(m1)), 
+     data = list(x = orob1))
\end{Sinput}
\end{Schunk}

\begin{Schunk}
\begin{Sinput}
> m2
\end{Sinput}
\begin{Soutput}
Call:
mle2(minuslogl = ml1, start = as.list(coef(m1)), data = list(x = orob1), 
    control = list(parscale = coef(m1)))

Coefficients:
       mu1        mu2        mu3      theta 
 0.1322117  0.8708922  0.8393198 78.4241320 

Log-likelihood: -34.99 
\end{Soutput}
\end{Schunk}

Calculate likelihood profile:
\begin{Schunk}
\begin{Sinput}
> p2 <- profile(m2)
\end{Sinput}
\end{Schunk}

Get the curvature-based parameter standard
deviations (which are what Crowder used,
rather than likelihood profiles):
\begin{Schunk}
\begin{Sinput}
> round(sqrt(diag(vcov(m2))), 3)
\end{Sinput}
\begin{Soutput}
   mu1    mu2    mu3  theta 
 0.028  0.029  0.032 74.240 
\end{Soutput}
\end{Schunk}
We are slightly off Crowder's numbers --- rounding
error?

Crowder also defines a variance (overdispersion) parameter
$\sigma^2=1/(1+\theta)$.
\begin{Schunk}
\begin{Sinput}
> sqrt(1/(1 + coef(m2)["theta"]))
\end{Sinput}
\begin{Soutput}
    theta 
0.1122080 
\end{Soutput}
\end{Schunk}

Using the delta method to get the standard deviation of
$\sigma$:
\begin{Schunk}
\begin{Sinput}
> library(emdbook)
> sqrt(deltavar(sqrt(1/(1 + theta)), meanval = coef(m2)["theta"], 
+     vars = "theta", Sigma = vcov(m2)[4, 4]))
\end{Sinput}
\begin{Soutput}
[1] 0.0524421
\end{Soutput}
\end{Schunk}

Another way to fit in terms of $\sigma$ rather than $\theta$
is to compute $\theta=1/\sigma^2-1$ on the fly in a
formula:

\begin{Schunk}
\begin{Sinput}
> m2f <- mle2(y ~ dbetabinom(mu, size = n, theta = 1/sigma^2 - 
+     1), data = orob1, parameters = list(mu ~ dilution, sigma ~ 
+     1), start = list(mu = 0.5, sigma = 0.1))
> round(sqrt(diag(vcov(m2f))), 3)
\end{Sinput}
\begin{Soutput}
  mu.(Intercept)  mu.dilution1/25 mu.dilution1/625            sigma 
           0.028            0.040            0.042            0.052 
\end{Soutput}
\end{Schunk}

As might be expected since the standard deviation
of $\sigma$ is large, the quadratic approximation is
not actually very good:

\begin{Schunk}
\begin{Sinput}
> r1 <- rbind(confint(p2)["theta", ], confint(m2, method = "quad")["theta", 
+     ])
> rownames(r1) <- c("spline", "quad")
> r1
\end{Sinput}
\begin{Soutput}
           2.5 %   97.5 %
spline  19.81835       NA
quad   -67.08388 223.9321
\end{Soutput}
\end{Schunk}

Plot the profile:
\begin{Schunk}
\begin{Sinput}
> plot(p2, which = "theta", plot.confstr = TRUE)
\end{Sinput}
\end{Schunk}
\includegraphics{mle2-025}

Now fit a homogeneous model:
\begin{Schunk}
\begin{Sinput}
> ml0 <- function(mu, theta, x) {
+     size <- x$n
+     -sum(dbetabinom(x$y, mu, size, theta, log = TRUE))
+ }
> m0 <- mle2(ml0, start = list(mu = 0.5, theta = 100), data = list(x = orob1))
\end{Sinput}
\end{Schunk}

The log-likelihood matches Crowder's result:
\begin{Schunk}
\begin{Sinput}
> logLik(m0)
\end{Sinput}
\begin{Soutput}
'log Lik.' -56.25774 (df=2)
\end{Soutput}
\end{Schunk}

It will be easier to specify all three of the models
fitted by Crowder (homogeneous, probabilities differing
by group, probabilities and overdispersion differing
by group) using the formulat interface:

\begin{Schunk}
\begin{Sinput}
> m0f <- mle2(y ~ dbetabinom(mu, size = n, theta), parameters = list(mu ~ 
+     1, theta ~ 1), data = orob1, start = list(mu = 0.5, theta = 100))
> m2f <- mle2(y ~ dbetabinom(mu, size = n, theta), parameters = list(mu ~ 
+     dilution, theta ~ 1), data = orob1, start = list(mu = 0.5, 
+     theta = 78.424))
> m3f <- mle2(y ~ dbetabinom(mu, size = n, theta), parameters = list(mu ~ 
+     dilution, theta ~ dilution), data = orob1, start = list(mu = 0.5, 
+     theta = 78.424))
\end{Sinput}
\end{Schunk}

\code{anova} runs a likelihood ratio test on nested
models:
\begin{Schunk}
\begin{Sinput}
> anova(m0f, m2f, m3f)
\end{Sinput}
\begin{Soutput}
Likelihood Ratio Tests
Model 1: m0f, y~dbetabinom(mu,size=n,theta): mu~1, theta~1
Model 2: m2f, y~dbetabinom(mu,size=n,theta): mu~dilution, theta~1
Model 3: m3f, y~dbetabinom(mu,size=n,theta): mu~dilution, theta~dilution
  Tot Df Deviance   Chisq Df Pr(>Chisq)    
1      2  112.515                          
2      4   69.981 42.5341  2  5.805e-10 ***
3      6   69.981  0.0008  2     0.9996    
---
Signif. codes:  0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 
\end{Soutput}
\end{Schunk}

The various \code{ICtab} commands produce tables of
information criteria, optionally sorted and
with model weights.
\begin{Schunk}
\begin{Sinput}
> AICtab(m0f, m2f, m3f, weights = TRUE, delta = TRUE, sort = TRUE)
\end{Sinput}
\begin{Soutput}
    AIC   df dAIC  weight
m2f  78.0 4    0.0 0.881 
m3f  82.0 6    4.0 0.119 
m0f 116.5 2   38.5 <0.001
\end{Soutput}
\begin{Sinput}
> BICtab(m0f, m2f, m3f, delta = TRUE, nobs = nrow(orob1), sort = TRUE, 
+     weights = TRUE)
\end{Sinput}
\begin{Soutput}
    BIC   df dBIC  weight
m2f  81.1 4    0.0 0.9412
m3f  86.6 6    5.5 0.0588
m0f 118.1 2   37.0 <0.001
\end{Soutput}
\begin{Sinput}
> AICctab(m0f, m2f, m3f, delta = TRUE, nobs = nrow(orob1), sort = TRUE, 
+     weights = TRUE)
\end{Sinput}
\begin{Soutput}
    AICc  df dAICc weight 
m2f  81.6 4    0.0 0.99222
m3f  91.3 6    9.7 0.00778
m0f 117.4 2   35.8 < 0.001
\end{Soutput}
\end{Schunk}

\begin{itemize}
\item{anova method}
\item{warnings on convergence failure}
\item{more robust to non-positive-definite Hessian}
\item{when profiling fails because better value is
    found, report new values}
\item{can take named vectors as well as lists as
    starting parameter vectors}
\item{added optional arguments to AIC
    (corr, nobs, delta), BIC, confint 
    (method=c("spline","uniroot","quad"))}
\item{more options for colors and line types
    in profile plots}
\item{mle.options()}
\item{data= argument}
\item{handling of names in argument lists}
\end{itemize}

Wish list:
\begin{itemize}
\item{variable-length chunks in argument list}
\item{limited automatic differentiation
    (add capability for common distributions)}
\item{ability to use alternate optimizers (e.g. nlmin/b)}
\end{itemize}

\bibliography{mle2}
\end{document}
